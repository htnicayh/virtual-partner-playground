<!doctype html>
<html lang="en">
	<head>
		<meta charset="UTF-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<title>Virtual Partner Playground</title>
		<script src="https://cdn.socket.io/4.8.2/socket.io.min.js"></script>
		<style>
			* {
				margin: 0;
				padding: 0;
				box-sizing: border-box;
			}

			body {
				font-family:
					-apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen', 'Ubuntu', 'Cantarell', 'Fira Sans',
					'Droid Sans', 'Helvetica Neue', sans-serif;
				background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
				min-height: 100vh;
				display: flex;
				padding: 20px;
				gap: 20px;
			}

			.main-content {
				display: flex;
				gap: 20px;
				width: 100%;
				max-width: 1200px;
				margin: 0 auto;
			}

			.container {
				background: white;
				border-radius: 12px;
				box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
				max-width: 600px;
				width: 100%;
				padding: 40px;
				flex: 1;
			}

			.chat-sidebar {
				background: white;
				border-radius: 12px;
				box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
				width: 350px;
				padding: 20px;
				display: flex;
				flex-direction: column;
			}

			.sidebar-title {
				font-size: 16px;
				font-weight: 700;
				color: #333;
				margin-bottom: 15px;
				border-bottom: 2px solid #667eea;
				padding-bottom: 10px;
			}

			.sidebar-messages {
				flex: 1;
				overflow-y: auto;
				display: flex;
				flex-direction: column;
				gap: 10px;
			}

			.sidebar-message {
				padding: 10px 12px;
				border-radius: 6px;
				font-size: 12px;
				line-height: 1.4;
			}

			.sidebar-message.user {
				background: #e3f2fd;
				border-left: 3px solid #667eea;
				text-align: right;
			}

			.sidebar-message.assistant {
				background: #f1f8e9;
				border-left: 3px solid #4caf50;
			}

			h1 {
				text-align: center;
				color: #333;
				margin-bottom: 10px;
				font-size: 28px;
			}

			.subtitle {
				text-align: center;
				color: #666;
				margin-bottom: 30px;
				font-size: 14px;
			}

			.status {
				background: #f5f5f5;
				border-left: 4px solid #667eea;
				padding: 12px 15px;
				margin-bottom: 20px;
				border-radius: 4px;
				font-size: 14px;
			}

			.status.connected {
				border-left-color: #4caf50;
				background: #e8f5e9;
			}

			.status.disconnected {
				border-left-color: #f44336;
				background: #ffebee;
			}

			.status.recording {
				border-left-color: #ff9800;
				background: #fff3e0;
			}

			.status.processing {
				border-left-color: #2196f3;
				background: #e3f2fd;
			}

			.status-text {
				font-weight: 600;
				color: #333;
			}

			.controls {
				display: flex;
				gap: 10px;
				margin-bottom: 30px;
				flex-wrap: wrap;
			}

			button {
				flex: 1;
				min-width: 60px;
				padding: 10px 12px;
				border: none;
				border-radius: 6px;
				font-size: 12px;
				font-weight: 600;
				cursor: pointer;
				transition: all 0.3s ease;
			}

			button:hover {
				transform: translateY(-2px);
				box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
			}

			button:disabled {
				opacity: 0.5;
				cursor: not-allowed;
				transform: none;
			}

			.btn-primary {
				background: #667eea;
				color: white;
			}

			.btn-primary:hover:not(:disabled) {
				background: #5568d3;
			}

			.btn-danger {
				background: #f44336;
				color: white;
			}

			.btn-danger:hover:not(:disabled) {
				background: #da190b;
			}

			.btn-success {
				background: #4caf50;
				color: white;
			}

			.btn-success:hover:not(:disabled) {
				background: #388e3c;
			}

			.info-section {
				margin-bottom: 25px;
			}

			.section-title {
				font-size: 12px;
				font-weight: 700;
				text-transform: uppercase;
				color: #999;
				margin-bottom: 8px;
				letter-spacing: 0.5px;
			}

			.transcript-box,
			.response-box,
			.timings-box {
				background: #f9f9f9;
				border: 1px solid #e0e0e0;
				border-radius: 6px;
				padding: 12px;
				min-height: 60px;
				max-height: 120px;
				overflow-y: auto;
				font-size: 13px;
				line-height: 1.5;
				color: #333;
			}

			.empty-text {
				color: #999;
				font-style: italic;
			}

			.processing-indicator {
				display: none;
				text-align: center;
				padding: 20px;
				color: #667eea;
			}

			.processing-indicator.active {
				display: block;
			}

			.spinner {
				display: inline-block;
				width: 20px;
				height: 20px;
				border: 3px solid #f3f3f3;
				border-top: 3px solid #667eea;
				border-radius: 50%;
				animation: spin 1s linear infinite;
			}

			@keyframes spin {
				0% {
					transform: rotate(0deg);
				}

				100% {
					transform: rotate(360deg);
				}
			}

			.loading-skeleton {
				display: flex;
				flex-direction: column;
				gap: 8px;
			}

			.skeleton-line {
				height: 12px;
				background: linear-gradient(90deg, #e0e0e0 25%, #f0f0f0 50%, #e0e0e0 75%);
				background-size: 200% 100%;
				border-radius: 4px;
				animation: loading 1.5s infinite;
			}

			.skeleton-line:last-child {
				width: 80%;
			}

			@keyframes loading {
				0% {
					background-position: 200% 0;
				}

				100% {
					background-position: -200% 0;
				}
			}

			.metrics {
				display: grid;
				grid-template-columns: 1fr 1fr;
				gap: 10px;
				margin-top: 15px;
			}

			.metric {
				background: #f5f5f5;
				padding: 10px;
				border-radius: 4px;
				text-align: center;
				font-size: 12px;
			}

			.metric-value {
				font-size: 16px;
				font-weight: 700;
				color: #667eea;
			}

			.metric-label {
				color: #999;
				margin-top: 3px;
			}

			.log-container {
				background: #1e1e1e;
				color: #d4d4d4;
				border-radius: 6px;
				padding: 12px;
				font-family: 'Courier New', monospace;
				font-size: 11px;
				max-height: 200px;
				overflow-y: auto;
				margin-top: 20px;
			}

			.log-entry {
				padding: 3px 0;
				border-bottom: 1px solid #333;
			}

			.log-entry:last-child {
				border-bottom: none;
			}

			.log-time {
				color: #858585;
			}

			.log-message {
				color: #d4d4d4;
			}

			.log-error {
				color: #f48771;
			}

			.log-success {
				color: #89d185;
			}

			.audio-visualization {
				display: none;
				margin-bottom: 20px;
			}

			.audio-visualization.active {
				display: block;
			}

			canvas {
				width: 100%;
				height: 100px;
				border: 1px solid #e0e0e0;
				border-radius: 6px;
				background: #f9f9f9;
			}

			.btn-warning {
				background: #ff9800;
				color: white;
			}

			.btn-warning:hover:not(:disabled) {
				background: #f57c00;
			}

			.chat-display {
				background: #f5f5f5;
				border-radius: 6px;
				padding: 15px;
				margin-bottom: 20px;
				max-height: 300px;
				overflow-y: auto;
			}

			.chat-display-message {
				padding: 10px 12px;
				margin-bottom: 8px;
				border-radius: 4px;
				font-size: 13px;
				line-height: 1.4;
			}

			.chat-display-message.user {
				background: #e3f2fd;
				border-left: 3px solid #667eea;
				text-align: right;
			}

			.chat-display-message.assistant {
				background: #f1f8e9;
				border-left: 3px solid #4caf50;
			}
		</style>
	</head>

	<body>
		<div class="main-content">
			<div class="container">
				<h1>Virtual Partner Playground</h1>
				<p class="subtitle">Live API Duplex Streaming (PCM)</p>

				<div class="status disconnected" id="status">
					<span class="status-text" id="statusText">Disconnected</span>
				</div>

				<div class="controls">
					<button class="btn-primary" id="recordBtn" onclick="startRecording()" disabled>Record</button>
					<button class="btn-primary" id="finishBtn" onclick="finishRecording()" disabled>Finish</button>
					<button class="btn-danger" id="stopBtn" onclick="stopSession()" disabled>Stop</button>
					<button class="btn-danger" id="cancelBtn" onclick="cancelStream()" disabled>Cancel</button>
				</div>

				<div class="audio-visualization" id="visualization">
					<div class="section-title">Audio Waveform</div>
					<canvas id="audioCanvas"></canvas>
				</div>

				<div class="processing-indicator" id="processing">
					<div class="spinner"></div>
					<p id="processingText" style="margin-top: 10px; font-size: 13px"></p>
				</div>

				<div class="info-section">
					<div class="section-title">Your Transcription</div>
					<div class="transcript-box" id="transcript">
						<span class="empty-text">Waiting for audio...</span>
					</div>
				</div>

				<div class="info-section">
					<div class="section-title">AI Response</div>
					<div class="response-box" id="response">
						<span class="empty-text">Waiting for response...</span>
					</div>
				</div>

				<div class="info-section">
					<div class="section-title">Processing Metrics</div>
					<div class="metrics">
						<div class="metric">
							<div class="metric-value" id="bytesMetric">0</div>
							<div class="metric-label">Bytes Sent</div>
						</div>
						<div class="metric">
							<div class="metric-value" id="chunksMetric">0</div>
							<div class="metric-label">Chunks Sent</div>
						</div>
						<div class="metric">
							<div class="metric-value" id="timeMetric">0ms</div>
							<div class="metric-label">Processing Time</div>
						</div>
						<div class="metric">
							<div class="metric-value" id="recordTimeMetric">0s</div>
							<div class="metric-label">Recording Time</div>
						</div>
					</div>
				</div>

				<div class="log-container" id="logs"></div>
			</div>

			<div class="chat-sidebar">
				<div class="sidebar-title">üí¨ Chat History</div>
				<div class="sidebar-messages" id="sidebarMessages">
					<p style="text-align: center; color: #999; font-size: 12px">Start recording to see messages...</p>
				</div>
			</div>
		</div>

		<script>
			let socket = null
			let audioContext = null
			let processor = null
			let source = null
			let mediaStream = null
			let isRecording = false
			let recordingStartTime = null
			let recordingInterval = null
			let totalBytesSent = 0
			let chunksSent = 0
			let displayedMessages = new Set()
			let conversationId = null

			let audioOutputContext = null
			let audioQueue = []
			let isPlaying = false

			const SERVER_URL = 'ws://localhost:3000'
			// const SERVER_URL = 'wss://virtual-partner-backend-production.up.railway.app'

			function log(message, type = 'message') {
				const logsContainer = document.getElementById('logs')
				const entry = document.createElement('div')

				entry.className = 'log-entry'

				const time = new Date().toLocaleTimeString('en-US', {
					hour12: false,
					hour: '2-digit',
					minute: '2-digit',
					second: '2-digit'
				})

				let html = `<span class="log-time">${time}</span> `

				if (type === 'error') {
					html += `<span class="log-error">‚ùå ${message}</span>`
				} else if (type === 'success') {
					html += `<span class="log-success">‚úì ${message}</span>`
				} else {
					html += `<span class="log-message">‚Üí ${message}</span>`
				}

				entry.innerHTML = html

				logsContainer.appendChild(entry)
				logsContainer.scrollTop = logsContainer.scrollHeight
			}

			function updateStatus(text, type) {
				const statusEl = document.getElementById('status')
				const statusText = document.getElementById('statusText')

				statusEl.className = `status ${type}`
				statusText.textContent = text
			}

			function updateMetrics() {
				document.getElementById('bytesMetric').textContent = (totalBytesSent / 1024).toFixed(2) + ' KB'
				document.getElementById('chunksMetric').textContent = chunksSent

				if (recordingStartTime) {
					const elapsed = ((Date.now() - recordingStartTime) / 1000).toFixed(1)
					document.getElementById('recordTimeMetric').textContent = elapsed + 's'
				}
			}

			function addChatMessage(text, role) {
				const messageKey = `${role}:${text}`

				if (displayedMessages.has(messageKey)) {
					return
				}

				displayedMessages.add(messageKey)

				const sidebarMessages = document.getElementById('sidebarMessages')

				if (sidebarMessages.children[0]?.textContent.includes('Start recording')) {
					sidebarMessages.innerHTML = ''
					displayedMessages.clear()
				}

				const messageEl = document.createElement('div')
				messageEl.className = `sidebar-message ${role}`
				messageEl.textContent = text

				sidebarMessages.appendChild(messageEl)
				sidebarMessages.scrollTop = sidebarMessages.scrollHeight
			}

			function showProcessing(text) {
				const processing = document.getElementById('processing')
				document.getElementById('processingText').textContent = text
				processing.classList.add('active')
			}

			function hideProcessing() {
				document.getElementById('processing').classList.remove('active')
			}

			async function playAudioQueue() {
				while (true) {
					if (audioQueue.length === 0) {
						isPlaying = false
						await new Promise((resolve) => setTimeout(resolve, 50))
						continue
					}

					if (!audioOutputContext) {
						audioOutputContext = new (window.AudioContext || window.webkitAudioContext)({
							sampleRate: 24000
						})
					}

					isPlaying = true
					const base64Audio = audioQueue.shift()

					try {
						// Decode base64 to Int16 PCM
						const binaryString = atob(base64Audio)
						const bytes = new Uint8Array(binaryString.length)

						for (let i = 0; i < binaryString.length; i++) {
							bytes[i] = binaryString.charCodeAt(i)
						}

						// Convert Int16 to Float32 for AudioContext
						const int16Array = new Int16Array(bytes.buffer)
						const float32Array = new Float32Array(int16Array.length)

						for (let i = 0; i < int16Array.length; i++) {
							float32Array[i] = int16Array[i] / 32768.0
						}

						// Create and play audio buffer
						const audioBuffer = audioOutputContext.createBuffer(1, float32Array.length, 24000)

						audioBuffer.getChannelData(0).set(float32Array)

						const source = audioOutputContext.createBufferSource()

						source.buffer = audioBuffer
						source.connect(audioOutputContext.destination)

						// Wait for playback to complete
						await new Promise((resolve) => {
							source.onended = resolve
							source.start()
						})
					} catch (e) {
						log(`Audio playback error: ${e.message}`, 'error')
					}
				}
			}

			// Start playback loop
			playAudioQueue()

			async function connect() {
				try {
					updateStatus('Connecting...', 'processing')
					log('Attempting to connect to server...')

					socket = io(SERVER_URL + '/audio', {
						reconnection: true,
						reconnectionDelay: 1000,
						reconnectionDelayMax: 5000,
						reconnectionAttempts: 5
					})

					socket.on('connect', () => {
						updateStatus('Connected', 'connected')
						log('Connected to server', 'success')

						document.getElementById('recordBtn').disabled = false
					})

					socket.on('disconnect', () => {
						updateStatus('Disconnected', 'disconnected')
						log('Disconnected from server', 'error')

						document.getElementById('recordBtn').disabled = true
						document.getElementById('finishBtn').disabled = true
						document.getElementById('stopBtn').disabled = true

						isRecording = false
					})

					socket.on('live-session-ready', (data) => {
						log('Live API session ready', 'success')
					})

					socket.on('live-audio-chunk', async (data) => {
						log('Received audio chunk from AI')
						audioQueue.push(data.audio)
					})

					socket.on('live-transcript', (data) => {
						document.getElementById('response').textContent = data.text
						log(`AI transcript: "${data.text.substring(0, 50)}..."`, 'success')
						addChatMessage(data.text, 'assistant')
					})

					socket.on('live-interrupted', () => {
						log('AI response interrupted', 'message')
						audioQueue = []
					})

					socket.on('stream-started', (data) => {
						log('Stream started', 'success')
						showProcessing('Recording audio...')
					})

					socket.on('chunk-received', (data) => {
						// Silent
					})

					socket.on('user-transcript', (data) => {
						document.getElementById('transcript').textContent = data.text
						log('Transcription received', 'success')
						addChatMessage(data.text, 'user')
					})

					socket.on('processing', (data) => {
						showProcessing(`Processing: ${data.status}`)
						log(`Status: ${data.status}`)
					})

					socket.onAny((eventName, ...args) => {
						if (eventName !== 'chunk-received') {
							log(`Event received: ${eventName}`, 'message')
						}
					})

					socket.on('error', (data) => {
						log(`Error: ${data.message}`, 'error')
						updateStatus(`Error: ${data.code}`, 'disconnected')
					})
				} catch (error) {
					log(`Connection error: ${error.message}`, 'error')
				}
			}

			async function startRecording() {
				try {
					log('Starting recording...')

					// Get mic with PCM settings (like verify-liveapi.js)
					mediaStream = await navigator.mediaDevices.getUserMedia({
						audio: {
							channelCount: 1,
							sampleRate: 16000,
							echoCancellation: true,
							noiseSuppression: true
						}
					})

					// Create AudioContext at 16kHz
					audioContext = new (window.AudioContext || window.webkitAudioContext)({
						sampleRate: 16000
					})

					source = audioContext.createMediaStreamSource(mediaStream)
					processor = audioContext.createScriptProcessor(4096, 1, 1)

					let chunkIndex = 0

					processor.onaudioprocess = (e) => {
						if (!isRecording) return

						const inputData = e.inputBuffer.getChannelData(0)

						// Convert Float32 to Int16 PCM
						const pcmData = new Int16Array(inputData.length)
						for (let i = 0; i < inputData.length; i++) {
							const s = Math.max(-1, Math.min(1, inputData[i]))
							pcmData[i] = s < 0 ? s * 0x8000 : s * 0x7fff
						}

						// Convert to base64 (like verify-liveapi.js)
						const buffer = new Uint8Array(pcmData.buffer)
						const base64 = btoa(String.fromCharCode.apply(null, buffer))

						socket.emit('audio-chunk', {
							chunk: base64,
							chunkIndex: chunkIndex++
						})

						totalBytesSent += buffer.length
						chunksSent++
					}

					source.connect(processor)
					processor.connect(audioContext.destination)

					conversationId = 'conv-' + Date.now()

					socket.emit('start-stream', {
						userId: 'user-' + Date.now(),
						sessionId: 'session-' + Date.now(),
						conversationId: conversationId
					})

					recordingStartTime = Date.now()
					totalBytesSent = 0
					chunksSent = 0

					isRecording = true

					updateStatus('Recording...', 'recording')
					log('Recording started (PCM 16kHz mode)', 'success')

					document.getElementById('recordBtn').disabled = true
					document.getElementById('finishBtn').disabled = false
					document.getElementById('stopBtn').disabled = false
					document.getElementById('cancelBtn').disabled = false

					recordingInterval = setInterval(updateMetrics, 1000)
				} catch (error) {
					log(`Recording error: ${error.message}`, 'error')
					updateStatus('Recording failed', 'disconnected')
				}
			}

			async function finishRecording() {
				try {
					log('Finishing recording...')

					isRecording = false

					if (processor) {
						processor.disconnect()
						source.disconnect()
					}

					if (mediaStream) {
						mediaStream.getTracks().forEach((track) => track.stop())
					}

					if (audioContext && audioContext.state !== 'closed') {
						await audioContext.close()
						audioContext = null
					}

					if (recordingInterval) {
						clearInterval(recordingInterval)
					}

					socket.emit('end-stream', {})

					updateStatus('Connected', 'connected')
					log('Recording finished', 'success')

					document.getElementById('recordBtn').disabled = false
					document.getElementById('finishBtn').disabled = true
					document.getElementById('stopBtn').disabled = false
					document.getElementById('cancelBtn').disabled = true

					recordingStartTime = null
				} catch (error) {
					log(`Finish error: ${error.message}`, 'error')
				}
			}

			async function stopSession() {
				try {
					log('Stopping session...')

					isRecording = false

					if (processor) {
						processor.disconnect()
						source.disconnect()
					}

					if (mediaStream) {
						mediaStream.getTracks().forEach((track) => track.stop())
					}

					if (audioContext && audioContext.state !== 'closed') {
						await audioContext.close()
						audioContext = null
					}

					if (recordingInterval) {
						clearInterval(recordingInterval)
					}

					await new Promise((resolve) => setTimeout(resolve, 100))

					socket.emit('end-conversation', {
						conversationId: conversationId
					})

					updateStatus('Connected', 'connected')
					log('Session stopped', 'success')

					document.getElementById('recordBtn').disabled = false
					document.getElementById('finishBtn').disabled = true
					document.getElementById('stopBtn').disabled = true
					document.getElementById('cancelBtn').disabled = true

					recordingStartTime = null
					totalBytesSent = 0
					chunksSent = 0
					updateMetrics()
				} catch (error) {
					log(`Stop error: ${error.message}`, 'error')
				}
			}

			async function cancelStream() {
				try {
					log('Cancelling stream...')

					isRecording = false

					if (processor) {
						processor.disconnect()
						source.disconnect()
					}

					if (mediaStream) {
						mediaStream.getTracks().forEach((track) => track.stop())
					}

					if (audioContext && audioContext.state !== 'closed') {
						await audioContext.close()
						audioContext = null
					}

					if (recordingInterval) {
						clearInterval(recordingInterval)
					}

					await new Promise((resolve) => setTimeout(resolve, 100))

					socket.emit('cancel-stream', {
						sessionId: 'session-' + Date.now()
					})

					updateStatus('Connected', 'connected')
					log('Stream cancelled', 'success')

					document.getElementById('recordBtn').disabled = false
					document.getElementById('finishBtn').disabled = true
					document.getElementById('stopBtn').disabled = false
					document.getElementById('cancelBtn').disabled = true

					recordingStartTime = null
				} catch (error) {
					log(`Cancel error: ${error.message}`, 'error')
				}
			}

			window.addEventListener('load', () => {
				log('Page loaded')
				connect()
				setInterval(updateMetrics, 1000)
			})

			window.addEventListener('beforeunload', () => {
				if (socket) {
					socket.disconnect()
				}
			})
		</script>
	</body>
</html>
